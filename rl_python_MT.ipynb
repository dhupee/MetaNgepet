{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_python_MT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrxc7zbuO6CeopI7qrmj7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python374jvsc74a57bd05272e271198e641207f4d8bec6a72159b91d0337ccfbc75f7129e4987471b9d3",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhupee/MT5_TensorDL/blob/main/rl_python_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7poR1bn64i6U",
        "outputId": "7ac9a299-f386-45bf-8407-c6a8a54e78bc"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hM9SNTx4BLj",
        "outputId": "86edd07e-8d26-44da-dca7-b079272dee1c"
      },
      "source": [
        "!pip install MetaTrader5==5.0.34\n",
        "!pip install gym-anytrading"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: MetaTrader5==5.0.34 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (5.0.34)\n",
            "Requirement already satisfied: numpy>=1.7 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from MetaTrader5==5.0.34) (1.16.5)\n",
            "Collecting gym-anytrading\n",
            "  Downloading https://files.pythonhosted.org/packages/12/fe/80fb1c8e74e58dc9854f30dd5fed38038dc3c37208e8bb87fc01520d0499/gym_anytrading-1.2.0-py3-none-any.whl (171kB)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from gym-anytrading) (3.2.2)\n",
            "Requirement already satisfied: gym>=0.12.5 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from gym-anytrading) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from gym-anytrading) (1.16.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from gym-anytrading) (0.25.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->gym-anytrading) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->gym-anytrading) (2.8.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->gym-anytrading) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->gym-anytrading) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->gym-anytrading) (2019.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->gym-anytrading) (41.4.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dhupee\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=3.1.1->gym-anytrading) (1.12.0)\n",
            "Installing collected packages: gym-anytrading\n",
            "Successfully installed gym-anytrading-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "u49H4BR53g8y",
        "outputId": "dce1249f-6705-45c7-8859-c258a7b0f42a"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pylab as plt\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import MetaTrader5 as mt5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjvzF3xU31Ov"
      },
      "source": [
        "MAX_EPSILON = 1\n",
        "MIN_EPSILON = 0.01\n",
        "LAMBDA = 0.0001\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 50"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self, num_states, num_actions, batch_size):\n",
        "        self._num_states = num_states\n",
        "        self._num_actions = num_actions\n",
        "        self._batch_size = batch_size\n",
        "        # define the placeholders\n",
        "        self._states = None\n",
        "        self._actions = None\n",
        "        # the output operations\n",
        "        self._logits = None\n",
        "        self._optimizer = None\n",
        "        self._var_init = None\n",
        "        # now setup the model\n",
        "        self._define_model()\n",
        "\n",
        "    def _define_model(self):\n",
        "        self._states = tf.placeholder(shape=[None, self._num_states], dtype=tf.float32)\n",
        "        self._q_s_a = tf.placeholder(shape=[None, self._num_actions], dtype=tf.float32)\n",
        "        # create a couple of fully connected hidden layers\n",
        "        fc1 = tf.layers.dense(self._states, 50, activation=tf.nn.relu)\n",
        "        fc2 = tf.layers.dense(fc1, 50, activation=tf.nn.relu)\n",
        "        self._logits = tf.layers.dense(fc2, self._num_actions)\n",
        "        loss = tf.losses.mean_squared_error(self._q_s_a, self._logits)\n",
        "        self._optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
        "        self._var_init = tf.global_variables_initializer()\n",
        "\n",
        "    def predict_one(self, state, sess):\n",
        "        return sess.run(self._logits, feed_dict={self._states:\n",
        "                                                     state.reshape(1, self.num_states)})\n",
        "\n",
        "    def predict_batch(self, states, sess):\n",
        "        return sess.run(self._logits, feed_dict={self._states: states})\n",
        "\n",
        "    def train_batch(self, sess, x_batch, y_batch):\n",
        "        sess.run(self._optimizer, feed_dict={self._states: x_batch, self._q_s_a: y_batch})\n",
        "\n",
        "    @property\n",
        "    def num_states(self):\n",
        "        return self._num_states\n",
        "\n",
        "    @property\n",
        "    def num_actions(self):\n",
        "        return self._num_actions\n",
        "\n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self._batch_size\n",
        "\n",
        "    @property\n",
        "    def var_init(self):\n",
        "        return self._var_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Memory:\n",
        "    def __init__(self, max_memory):\n",
        "        self._max_memory = max_memory\n",
        "        self._samples = []\n",
        "\n",
        "    def add_sample(self, sample):\n",
        "        self._samples.append(sample)\n",
        "        if len(self._samples) > self._max_memory:\n",
        "            self._samples.pop(0)\n",
        "\n",
        "    def sample(self, no_samples):\n",
        "        if no_samples > len(self._samples):\n",
        "            return random.sample(self._samples, len(self._samples))\n",
        "        else:\n",
        "            return random.sample(self._samples, no_samples)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "nT284hcB2toW",
        "outputId": "cd9de226-b507-4306-d904-7732e69bf485"
      },
      "source": [
        "class GameRunner:\n",
        "    def __init__(self, sess, model, env, memory, max_eps, min_eps,\n",
        "                 decay, render=True):\n",
        "        self._sess = sess\n",
        "        self._env = env\n",
        "        self._model = model\n",
        "        self._memory = memory\n",
        "        self._render = render\n",
        "        self._max_eps = max_eps\n",
        "        self._min_eps = min_eps\n",
        "        self._decay = decay\n",
        "        self._eps = self._max_eps\n",
        "        self._steps = 0\n",
        "        self._reward_store = []\n",
        "        self._max_x_store = []\n",
        "\n",
        "    def run(self):\n",
        "        state = self._env.reset()\n",
        "        tot_reward = 0\n",
        "        max_x = -100\n",
        "        while True:\n",
        "            if self._render:\n",
        "                self._env.render()\n",
        "\n",
        "            action = self._choose_action(state)\n",
        "            next_state, reward, done, info = self._env.step(action)\n",
        "            if next_state[0] >= 0.1:\n",
        "                reward += 10\n",
        "            elif next_state[0] >= 0.25:\n",
        "                reward += 20\n",
        "            elif next_state[0] >= 0.5:\n",
        "                reward += 100\n",
        "\n",
        "            if next_state[0] > max_x:\n",
        "                max_x = next_state[0]\n",
        "            # is the game complete? If so, set the next state to\n",
        "            # None for storage sake\n",
        "            if done:\n",
        "                next_state = None\n",
        "\n",
        "            self._memory.add_sample((state, action, reward, next_state))\n",
        "            self._replay()\n",
        "\n",
        "            # exponentially decay the eps value\n",
        "            self._steps += 1\n",
        "            self._eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) \\\n",
        "                                      * math.exp(-LAMBDA * self._steps)\n",
        "\n",
        "            # move the agent to the next state and accumulate the reward\n",
        "            state = next_state\n",
        "            tot_reward += reward\n",
        "\n",
        "            # if the game is done, break the loop\n",
        "            if done:\n",
        "                self._reward_store.append(tot_reward)\n",
        "                self._max_x_store.append(max_x)\n",
        "                break\n",
        "\n",
        "        print(\"Step {}, Total reward: {}, Eps: {}\".format(self._steps, tot_reward, self._eps))\n",
        "\n",
        "    def _choose_action(self, state):\n",
        "        if random.random() < self._eps:\n",
        "            return random.randint(0, self._model.num_actions - 1)\n",
        "        else:\n",
        "            return np.argmax(self._model.predict_one(state, self._sess))\n",
        "\n",
        "    def _replay(self):\n",
        "        batch = self._memory.sample(self._model.batch_size)\n",
        "        states = np.array([val[0] for val in batch])\n",
        "        next_states = np.array([(np.zeros(self._model.num_states)\n",
        "                                 if val[3] is None else val[3]) for val in batch])\n",
        "        # predict Q(s,a) given the batch of states\n",
        "        q_s_a = self._model.predict_batch(states, self._sess)\n",
        "        # predict Q(s',a') - so that we can do gamma * max(Q(s'a')) below\n",
        "        q_s_a_d = self._model.predict_batch(next_states, self._sess)\n",
        "        # setup training arrays\n",
        "        x = np.zeros((len(batch), self._model.num_states))\n",
        "        y = np.zeros((len(batch), self._model.num_actions))\n",
        "        for i, b in enumerate(batch):\n",
        "            state, action, reward, next_state = b[0], b[1], b[2], b[3]\n",
        "            # get the current q values for all actions in state\n",
        "            current_q = q_s_a[i]\n",
        "            # update the q value for action\n",
        "            if next_state is None:\n",
        "                # in this case, the game completed after action, so there is no max Q(s',a')\n",
        "                # prediction possible\n",
        "                current_q[action] = reward\n",
        "            else:\n",
        "                current_q[action] = reward + GAMMA * np.amax(q_s_a_d[i])\n",
        "            x[i] = state\n",
        "            y[i] = current_q\n",
        "        self._model.train_batch(self._sess, x, y)\n",
        "\n",
        "    @property\n",
        "    def reward_store(self):\n",
        "        return self._reward_store\n",
        "\n",
        "    @property\n",
        "    def max_x_store(self):\n",
        "        return self._max_x_store\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env_name = 'MountainCar-v0'\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    num_states = env.env.observation_space.shape[0]\n",
        "    num_actions = env.env.action_space.n\n",
        "\n",
        "    model = Model(num_states, num_actions, BATCH_SIZE)\n",
        "    mem = Memory(50000)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(model.var_init)\n",
        "        gr = GameRunner(sess, model, env, mem, MAX_EPSILON, MIN_EPSILON,\n",
        "                        LAMBDA)\n",
        "        num_episodes = 300\n",
        "        cnt = 0\n",
        "        while cnt < num_episodes:\n",
        "            if cnt % 10 == 0:\n",
        "                print('Episode {} of {}'.format(cnt+1, num_episodes))\n",
        "            gr.run()\n",
        "            cnt += 1\n",
        "        plt.plot(gr.reward_store)\n",
        "        plt.show()\n",
        "        plt.close(\"all\")\n",
        "        plt.plot(gr.max_x_store)\n",
        "        plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001BAD5B05508>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "Episode 1 of 300\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-2e24502af853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Episode {} of {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_store\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-16-2e24502af853>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_choose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keys_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mdispatch_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPeekMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPM_REMOVE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTranslateMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatchMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}